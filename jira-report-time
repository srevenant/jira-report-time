#!/usr/bin/env python3
"""
Jira time reporter

License: GNU Affero
"""

import os
import sys
import re
import json
import dictlib
import sys
import openpyxl
import argparse
import traceback
import requests
#from jira.client import JIRA
#from jira.config import get_jira
from jira import JIRA
import datetime
import dateutil.parser
import json
import argparse
from slacker import Slacker

def warn(msg):
    print("{} {}".format(datetime.datetime.now(), msg))

DEBUG = True
def debug(msg):
    if DEBUG:
        warn(msg)

################################################################################
def didLog(workid, seconds):
    # check a historical db to see if we already logged time for this
    return False

################################################################################
class JiraData(object):
    pergrp = None
    perdev = None
    issues = None
    grpfield = None
    grpproj = None
    fieldMap = None

    ############################################################################
    def __init__(self, jira, date_start, date_end, grpfield=None, grpproj=None):
        self.date_start = date_start
        self.date_end = date_end
        self.jira = jira
        self.pergrp = dict()
        self.issues = dict()
        self.perdev = dict()
        self.worklogs = list()
        self.fieldMap = fieldMap = dict()
        self.grpfield = grpfield
        self.grpproj = grpproj
        if grpfield:
            # Make a map from field name -> field id
            for field in self.jira.fields():
                if self.fieldMap.get(field['name']):
                    warn("Collision of key {}: {} and {}".format(field['name'], self.fieldMap[field['name']], field['id']))
                else:
                    self.fieldMap[field['name']] = field['id']
            if not self.fieldMap.get(grpfield):
                print("Available fields:")
                for field in self.fieldMap:
                    print("\t" + field)
                sys.exit("\nABORT: Cannot find grouping field `{}`".format(grpfield))
        elif not grpproj:
            sys.exit("ABORT: Neither --groupfield nor --groupproject specified")

    ############################################################################
    def process_issue(self, issue, num):
        if self.grpfield:
            groups = ['INTERNAL']
            try:
                if issue.fields:
                    groups_map = getattr(issue.fields, self.fieldMap[self.grpfield])
                    if groups_map:
                        groups = [grp.value for grp in groups_map]
            except:
                pass
        elif self.grpproj:
            groups = [issue.fields.project.key] #"INTERNAL"] #grpprojs

        # map out only what we need so we don't have export problems
        self.issues[issue.key] = dictlib.Obj(
            key=issue.key,
            fields=dictlib.Obj(summary=issue.fields.summary))

        for wl in self.jira.worklogs(issue.key):
            updated = dateutil.parser.parse(wl.started).date()

            if self.date_start <= updated <= self.date_end:
                debug("{} Worklog {} {} {} {}".format(num, issue.key, updated, wl.updateAuthor.name, inHours(wl.timeSpentSeconds)))
                seconds = int(wl.timeSpentSeconds)

                # did we already log this in the past?
                if didLog(wl.id, seconds):
                    continue

                comment = ''
                try:
                    comment = wl.comment
                except:
                    pass

                # log entry
                log = dictlib.Obj(
                  groups=groups,
                  issue=issue.key,
                  updated=updated,
                  author=wl.updateAuthor.name,
                  seconds=seconds,
                  id=wl.id,
                  comment=comment
                )
                self.worklogs.append(log)

                # calc things per developer
                devwork = self.perdev.get(log.author)
                if not devwork:
                    devwork = self.perdev[log.author] = dictlib.Obj(issues=dict(), sum=0)
                if not devwork.issues.get(issue.key):
                    devwork.issues[issue.key] = dictlib.Obj(sum=0, logs=list(), key=issue.key)

                # append log to issues
                devwork.issues[issue.key].logs.append(log)
                # add to dev total
                devwork.sum = self.perdev[log.author].sum + seconds

                # add to dev/issue total
                devwork.issues[issue.key].sum = devwork.issues[issue.key].sum + seconds

                for grp in groups:
                    if not self.pergrp.get(grp):
                        self.pergrp[grp] = dictlib.Obj(
                            sum=0,
                            issues=dict()
                        )
                    pc = self.pergrp[grp]

                    pc.sum = pc.sum + seconds
                    if not pc.issues.get(issue.key):
                        pc.issues[issue.key] = dictlib.Obj(sum=0, logs=list(), key=issue.key)
                    pc.issues[issue.key].logs.append(log)
                    pc.issues[issue.key].sum = pc.issues[issue.key].sum + seconds

    def gather(self):

        # I would like to use this JQL, but it requires other plugins:
        #    issueFunction in workLogged("after {} before {}")
        # so instead we do it the hard way
        # the hammer approach, gather any changed issue-- easier for more recent, harder for older reports
        jql = 'updated > "{}"'.format(self.date_start.strftime("%Y-%m-%d"))
        if self.grpproj:
            grpprojs = re.split(r'\s*,\s*', self.grpproj)
            jql = 'project in ("{}") AND {}'.format('","'.join(grpprojs), jql)

        warn("JQL: " + jql)

        # api pagination, pita
        maxResults = 500
        cursor = 0
        while True:
            results = self.jira.search_issues(jql, maxResults=maxResults, startAt=cursor)
            debug("total={} maxResults={} startAt={}".format(results.total, results.maxResults, results.startAt))
            if cursor <= results.total: # == maxResults:
                cursor = cursor + maxResults
            else:
                break
            x = 1
            for issue in results:
                debug("{} Issue {} {}".format(x, issue.key, issue.fields.summary))
                self.process_issue(issue, x)
                x = x + 1

        return self


################################################################################
def inHours(seconds):
    hours = int(seconds/3600)
    mins = int((seconds%3600)/60)

    # do another mod by 15-min interval later
    return "{}.{}".format(hours, mins)

################################################################################
def main():

    # config via file or stdin
    config = dict(
        start='',
        days='',
        group_field='Client/s',
        group_project='',
        slack_apikey='',
        slack_channels='',
        jira_url='',
        jira_user='',
        jira_pass='',
    )
    parser = argparse.ArgumentParser()
    parser.add_argument('--config')
    args = parser.parse_args()
    if args.config:
        with open(args.config) as infile:
            config = dictlib.Obj(dictlib.union(config, json.load(infile)))
    else:
        warn("reading config from stdin, end with EOF")
        config = dictlib.Obj(dictlib.union(config, json.load(sys.stdin)))

    config.days = int(config.days)
    if config.get('start'):
        date_start = dateutil.parser.parse(config.start).date()
    else:
        today = datetime.datetime.now().date()
        date_start = today - datetime.timedelta(days=config.days)
        warn("Defaulting to start {} days ago: {}".format(config.days, date_start))

    date_end = date_start + datetime.timedelta(days=config.days)

    warn("Report for {} to {} ({} days)".format(date_start, date_end, config.days))

    ##############################################################################
    warn("Connecting to jira (" + config.jira_url + ")...")
    jira = JIRA(config.jira_url, auth=(config.jira_user, config.jira_pass))

    warn("Collecting data from jira...")
    data = JiraData(jira, date_start, date_end, grpfield=config.group_field, grpproj=config.group_project).gather()

    ##############################################################################
    warn("Building Report...")
    label = 'Group'
    if config.group_field:
        label = config.group_field.split("/")[0]
    elif config.group_project:
        label = 'Project'

    report_file = "Time Report {}~{}.xlsx".format(date_start, date_end)
    if os.path.exists(report_file):
        os.unlink(report_file)
    warn("output file: " + report_file)

    workbook = openpyxl.Workbook()
    sheet = workbook.active
    sheet.title = 'Summary'
    def output(row, *dup):
        sheet.append(row)
#        if dup:
#            print("\t".join(row))

    output([])
    output(["Time Summary from " + str(date_start) + " to " + str(date_end)])
    output(["Hours", label], True)

    for group in data.pergrp:
        output([inHours(data.pergrp[group].sum), group], True)

#    output(["----"])
    for group in data.pergrp:
        sheet = workbook.create_sheet(("Issues " + group)[:31])
        output([])
        output([group + " Issue Report"], True)
        output(["Hours", "Issue"])
        for issue in sorted(data.pergrp[group].issues.values(), key=lambda e: e.sum, reverse=True):
            output([inHours(issue.sum), issue.key + " " + data.issues[issue.key].fields.summary])

#    output(["----"])
    for group in data.pergrp:
        sheet = workbook.create_sheet(("Detail " + group)[:31])
        output([])
        output([group + " Detail Report"], True)
        output(["Hours", "Issue/Log Author", "(hours)"])
        for issue in sorted(data.pergrp[group].issues.values(), key=lambda e: e.sum, reverse=True):
            output([inHours(issue.sum), issue.key + " " + data.issues[issue.key].fields.summary])
            worklog = dict()
            for log in sorted(issue.logs, key=lambda e: e.seconds, reverse=True):
                key = log.author
                if log.comment:
                    key = key + ": " + log.comment
                if worklog.get(key):
                    worklog[key] = worklog[key] + float(inHours(log.seconds))
                else:
                    worklog[key] = float(inHours(log.seconds))
            for log in sorted(worklog.keys(), key=lambda e: worklog[e], reverse=True):
                output(['', log, worklog[log]])

    sheet = workbook.create_sheet("Per Person")
    for dev in data.perdev:
        output([])
        output([dev + " Detail Report"], True)
        output(["Hours", "Issue"])
        sum = 0

        for issue in sorted(data.perdev[dev].issues.values(), key=lambda e: e.sum, reverse=True):
            output([inHours(issue.sum), issue.key + " " + data.issues[issue.key].fields.summary])
            logs = data.perdev[dev].issues[issue.key].logs
            worklog = dict()
            for log in sorted(logs, key=lambda e: e.seconds, reverse=True):
                if log.author != dev:
                    continue
                msg = log.issue + " " + data.issues[log.issue].fields.summary
                key = ''
                if log.comment:
                    key = log.comment
                if not key:
                    key = '<no comment>'
                if worklog.get(key):
                    worklog[key] = worklog[key] + float(inHours(log.seconds))
                else:
                    worklog[key] = float(inHours(log.seconds))
            if len(worklog) > 1:
                for log in sorted(worklog.keys(), key=lambda e: worklog[e], reverse=True):
                    output(['', log, worklog[log]])

    workbook.save(report_file)
    warn(report_file)

    ##############################################################################
    # and upload to slack
    if config.slack_apikey and config.slack_channels:
        slack = Slacker(config.slack_apikey)
        response = slack.files.upload(report_file, channels=config.slack_channels)
        warn("Upload to slack {} status={}".format(config.slack_channels, response.successful))
    else:
        sys.exit("No slack configuration?  Not uploading results!")

    sys.exit(0)

################################################################################
if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        pass

